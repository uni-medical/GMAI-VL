# GMAI-VL & GMAI-VL-5.5M: A General Medical Vision-Language Model and Multimodal Dataset

Welcome to the GMAI-VL code repository, which accompanies the paper "GMAI-VL & GMAI-VL-5.5M: A General Medical Vision-Language Model and Multimodal Dataset." This repository provides the resources needed for reproducing the results and furthering research in medical AI through vision-language models.
This repository includes:

- **GMAI-VL**: A state-of-the-art general medical vision-language model.
- **GMAI-VL-5.5M**: A comprehensive multimodal medical dataset containing 5.5 million images and associated text, designed to support a wide range of medical AI research.

## ðŸš§ Coming Soon: Code, Dataset, and Model Weights ðŸš§

We are currently organizing and preparing the following resources for public release:

- **Code**: Full implementation of the GMAI-VL model, including training and evaluation scripts.
- **Dataset**: GMAI-VL-5.5M, a large-scale multimodal medical dataset.
- **Model Weights**: Model weights of our model GMAI-VL.

Stay tuned for upcoming updates!

## ðŸ“… Release Timeline

We are committed to making these resources available as soon as possible. Please watch this repository or check back regularly for updates.

## ðŸ”— Stay Connected

For inquiries, collaboration opportunities, or access requests, feel free to reach out via email or open a GitHub issue.

Thank you for your interest and support!
